{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "# os.chdir(\"/home/syful-is/softSVM/data/\")\n",
    "\n",
    "df=pd.read_csv(\"RQ3_relatedness_Filtered_data.csv\", encoding = 'latin-1', engine ='python')\n",
    "\n",
    "df = df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_source=[]\n",
    "q2_source=[]\n",
    "q1_purpose=[]\n",
    "q2_purpose=[]\n",
    "q1_content=[]\n",
    "q2_content=[]\n",
    "\n",
    "dict_labels_source = {\"Desktop App image\":0, \"Web browser image\":1, \"Mobile App image\":2, \"User-created Image\":3}\n",
    "dict_labels_purpose = {\"desired output\": 0, \"context\":1}\n",
    "dict_labels_content = {\"User Interface\": 0, \"Results\":1}\n",
    "\n",
    "for i in range(len(df['q1_source'])):\n",
    "    q1_source.append(dict_labels_source[df['q1_source'][i]])\n",
    "    q2_source.append(dict_labels_source[df['q2_source'][i]])\n",
    "    q1_purpose.append(dict_labels_purpose[df['q1_purpose'][i]])\n",
    "    q2_purpose.append(dict_labels_purpose[df['q2_purpose'][i]])\n",
    "    q1_content.append(dict_labels_content[df['q1_content'][i]])\n",
    "    q2_content.append(dict_labels_content[df['q2_content'][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import Levenshtein\n",
    "\n",
    "\n",
    "def convertCamelCase(name):\n",
    "    s1 = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', name)\n",
    "    finals = re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', s1).lower()\n",
    "    return finals\n",
    "\n",
    "\n",
    "def text_to_wordlist(text, remove_stopwords=True, stem_words=False, remove_punc=True):\n",
    "    text = str(text)\n",
    "    \n",
    "    text = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', 'URL', text)\n",
    "    \n",
    "    text = text.split()\n",
    "    \n",
    "    text2 = []\n",
    "    \n",
    "    for t in text:\n",
    "        splited = re.split(\"[.,' \\-!?:#^%*[$\\]+|_`\\)=<;{\\\"&>@/~(\\\\}\\\\\\]+\", t)\n",
    "        text2.extend(splited)\n",
    "    not_digits=[] \n",
    "    \n",
    "    for i in text2:\n",
    "        if i.isdigit():\n",
    "            not_digits.append(\"cc\")\n",
    "        else:\n",
    "            not_digits.append(i)\n",
    "    text4 = []\n",
    "    for c in not_digits:\n",
    "        if len(c) > 1:\n",
    "            if c[1].islower():\n",
    "                for k in c[1:]:\n",
    "                    if not k.islower():\n",
    "                        text4.append(convertCamelCase(c))\n",
    "                        break;\n",
    "                else:\n",
    "                    text4.append(c)\n",
    "            else:\n",
    "                text4.append(c)\n",
    "        else:\n",
    "            text4.append(c)\n",
    "\n",
    "    text5 = []\n",
    "    for t in text4:\n",
    "        splited = re.split(\"_\", t)\n",
    "        text5.extend(splited)\n",
    "    text6=[]\n",
    "    for x in text5:\n",
    "        if len(x)>1:\n",
    "            text6.append(x)\n",
    "\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text6 if not w in stops]\n",
    "\n",
    "    text = \" \".join(text)\n",
    "\n",
    "    text = re.sub(\"  \", \" \", text)\n",
    "    text = re.sub(\"   \", \" \", text)\n",
    "    text = re.sub(\"    \", \" \", text)\n",
    "    text = re.sub(\"[0-9]+\", \"CC\", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"couldn't\", \"could not \", text)\n",
    "    text = re.sub(r\"doesn’t\", \"does not \", text)\n",
    "    text = re.sub(r\"don't\", \"do not \", text)\n",
    "    text = re.sub(r\"won't\", \"will not \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'\", \"\", text)\n",
    "    text = re.sub(r\"\\\"\", \"\", text)\n",
    "    text = re.sub(r\"“\", \"\", text)\n",
    "    text = re.sub(r\"”\", \"\", text)\n",
    "\n",
    "    if remove_punc:\n",
    "        exclude = set(string.punctuation)\n",
    "        text = ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    if stem_words:\n",
    "        text = text.split()\n",
    "        stemmer = SnowballStemmer('english')\n",
    "        stemmed_words = [stemmer.stem(word) for word in text]\n",
    "        text = \" \".join(stemmed_words)\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "    return (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_image_text = []\n",
    "q2_image_text = []\n",
    "q1_process = []\n",
    "q2_process = []\n",
    "\n",
    "count = 1\n",
    "for index, row in df.iterrows():\n",
    "\n",
    "    q1_Body = text_to_wordlist(str(row['q1_Title'])+ \" \" +str(row['q1_Body'])+ \" \" +str(row['q1_AcceptedAnswerBody'])+\" \" + str(row['Q1_image_text_new']), remove_stopwords=True, stem_words=False, remove_punc=True)\n",
    "    q1_process.append(q1_Body)\n",
    "    q1_image_text.append(text_to_wordlist(str(row['Q1_image_text_new']), remove_stopwords=True, stem_words=False, remove_punc=True))\n",
    "\n",
    "    q2_Body = text_to_wordlist(str(row['q2_Title'])+ \" \" +str(row['q2_Body'])+ \" \" +str(row['q2_AcceptedAnswerBody'])+\" \" + str(row['Q1_image_text_new']), remove_stopwords=True, stem_words=False, remove_punc=True)\n",
    "    q2_process.append(q2_Body)\n",
    "    q2_image_text.append(text_to_wordlist(str(row['Q2_image_text_new']), remove_stopwords=True, stem_words=False, remove_punc=True))\n",
    "    \n",
    "    count+=1\n",
    "    \n",
    "print(count)\n",
    "\n",
    "df[\"q1_process\"] = q1_process\n",
    "df[\"q2_process\"] = q2_process\n",
    "df[\"q1_image_text\"] = q1_image_text\n",
    "df[\"q2_image_text\"] = q2_image_text\n",
    "\n",
    "dict={'Id':list(df['Id']), 'q1_text_process':list(df['q1_process']), 'q2_text_process':list(df['q2_process']),\n",
    "      'q1_image_text':list(df['q1_image_text']),'q2_image_text':list(df['q2_image_text']),\n",
    "      'class':list(df['Class']) }\n",
    "df=pd.DataFrame(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import nltk\n",
    "import numpy as np\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Model . . . \n",
      "google w2v loaded\n"
     ]
    }
   ],
   "source": [
    "print(\"loading Model . . . \")\n",
    "model =   KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "print(\"google w2v loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SO w2v loaded\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim import models\n",
    "embeddings_index = {}\n",
    "SO_file = 'textModel'\n",
    "model2 = models.KeyedVectors.load_word2vec_format('SO_vectors_200.bin',binary=True)\n",
    "print(\"SO w2v loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL fitted!\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 1), tokenizer=nltk.word_tokenize,\n",
    "                                             analyzer=\"word\", lowercase=True)\n",
    "tfidf_vectorizer.fit_transform(list(df['q1_text_process']) + list(df['q2_text_process']))\n",
    "\n",
    "its_vectorizer = TfidfVectorizer(ngram_range=(1, 1), tokenizer=nltk.word_tokenize,\n",
    "                                             analyzer=\"word\", lowercase=True) \n",
    "its_vectorizer.fit_transform(list(df['q1_image_text']) + list(df['q2_image_text']))\n",
    "print(\"MODEL fitted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def soft_w2v(q1, q2, model,fittedTFIDF):\n",
    "    if len(q1)==0 or len(q2)==0: return 0\n",
    "    matrix0, matrix1 ,featureNames = vectorizer(q1 , q2, fittedTFIDF)\n",
    "    index = []\n",
    "    for i in np.nonzero(matrix0)[0]:\n",
    "        index.append(i)\n",
    "    for i in np.nonzero(matrix1)[0]:\n",
    "        index.append(i)\n",
    "    index = sorted(set(index))\n",
    "    new_matrix0 = []\n",
    "    new_matrix1 = []\n",
    "    for l in index:\n",
    "        new_matrix0.append(matrix0[l])\n",
    "        new_matrix1.append(matrix1[l])\n",
    "    docs = []\n",
    "    docs.append(q1)\n",
    "    docs.append(q2)\n",
    "    featureNameLSZT = []\n",
    "    for g in index:\n",
    "        featureNameLSZT.append(featureNames[g])\n",
    "    matrix = matrixByw2v(featureNameLSZT, model)\n",
    "    npM0 = np.asarray(new_matrix0)\n",
    "    npM1 = np.asarray(new_matrix1)\n",
    "    tnpM0 = npM0.transpose()\n",
    "    tnpM1 = npM1.transpose()\n",
    "    dotProduct1 = np.dot(tnpM0, matrix)\n",
    "    dotproduct2 = np.dot(dotProduct1, npM1)\n",
    "    firstDomPartOne = np.dot(tnpM0, matrix)\n",
    "    firstDomPartTwo = np.dot(firstDomPartOne, npM0)\n",
    "    firstDominator = math.sqrt(firstDomPartTwo)\n",
    "    secondDomPartOne = np.dot(tnpM1, matrix)\n",
    "    secondDomPartTwo = np.dot(secondDomPartOne, npM1)\n",
    "    secondDominator = math.sqrt(secondDomPartTwo)\n",
    "    softCosineSimilarity = dotproduct2 / (firstDominator * secondDominator)\n",
    "    if np.count_nonzero(new_matrix0)==0 or np.count_nonzero(new_matrix1)==0:\n",
    "        return 0\n",
    "    return softCosineSimilarity\n",
    "\n",
    "def matrixByw2v(featureNames, model):\n",
    "\n",
    "    matrix = np.zeros((len(featureNames), len(featureNames))).astype('float')\n",
    "    # matrix =[[]]\n",
    "    for i in range(len(featureNames)):\n",
    "        for j in range(len(featureNames)):\n",
    "            if i == j:\n",
    "                matrix[i][j] = 1\n",
    "            else:\n",
    "                try:\n",
    "                    sim = model.similarity(featureNames[i], featureNames[j])\n",
    "                except KeyError:\n",
    "                    sim = 0\n",
    "                matrix[i][j] = (max(0, sim) * max(0, sim))\n",
    "    return matrix\n",
    "\n",
    "def vectorizer(question, parentQuestion, fittedTFIDF):\n",
    "    if len(question) == 0 or len(parentQuestion) == 0:\n",
    "        return [0]\n",
    "    documents = []\n",
    "    documents.append(question)\n",
    "    documents.append(parentQuestion)\n",
    "    tfidf_matrix = fittedTFIDF.transform(documents).toarray()\n",
    "    featureNames = fittedTFIDF.get_feature_names()\n",
    "    return tfidf_matrix[0], tfidf_matrix[1] ,featureNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "def soft_lev(q1, q2, model,fittedTFIDF):\n",
    "    if len(q1)==0 or len(q2)==0: return 0\n",
    "    matrix0, matrix1 ,featureNames = vectorizer(q1 , q2, fittedTFIDF)\n",
    "    index = []\n",
    "    for i in np.nonzero(matrix0)[0]:\n",
    "        index.append(i)\n",
    "    for i in np.nonzero(matrix1)[0]:\n",
    "        index.append(i)\n",
    "    index = sorted(set(index))\n",
    "    new_matrix0 = []\n",
    "    new_matrix1 = []\n",
    "    for l in index:\n",
    "        new_matrix0.append(matrix0[l])\n",
    "        new_matrix1.append(matrix1[l])\n",
    "    docs = []\n",
    "    docs.append(q1)\n",
    "    docs.append(q2)\n",
    "    featureNameLSZT = []\n",
    "    for g in index:\n",
    "        featureNameLSZT.append(featureNames[g])\n",
    "    matrix = matrixByLev(featureNameLSZT, model)\n",
    "    npM0 = np.asarray(new_matrix0)\n",
    "    npM1 = np.asarray(new_matrix1)\n",
    "    tnpM0 = npM0.transpose()\n",
    "    tnpM1 = npM1.transpose()\n",
    "    dotProduct1 = np.dot(tnpM0, matrix)\n",
    "    dotproduct2 = np.dot(dotProduct1, npM1)\n",
    "    firstDomPartOne = np.dot(tnpM0, matrix)\n",
    "    firstDomPartTwo = np.dot(firstDomPartOne, npM0)\n",
    "    firstDominator = math.sqrt(firstDomPartTwo)\n",
    "    secondDomPartOne = np.dot(tnpM1, matrix)\n",
    "    secondDomPartTwo = np.dot(secondDomPartOne, npM1)\n",
    "    secondDominator = math.sqrt(secondDomPartTwo)\n",
    "    softCosineSimilarity = dotproduct2 / (firstDominator * secondDominator)\n",
    "    if np.count_nonzero(new_matrix0)==0 or np.count_nonzero(new_matrix1)==0:\n",
    "        return 0\n",
    "    return softCosineSimilarity\n",
    "\n",
    "def matrixByLev(featureNames, model):\n",
    "\n",
    "    matrix = np.zeros((len(featureNames), len(featureNames))).astype('float')\n",
    "\n",
    "    for i in range(len(featureNames)):\n",
    "        for j in range(len(featureNames)):\n",
    "\n",
    "            if i == j:\n",
    "                matrix[i][j] = 1\n",
    "            else:\n",
    "\n",
    "                try:\n",
    "                    lev = Levenshtein.distance(featureNames[i], featureNames[j])\n",
    "                    lenfirst = len(featureNames[i])\n",
    "                    lensecond = len(featureNames[j])\n",
    "                    matrix[i][j] = 1.8 * (math.pow(1 - lev / max(lenfirst, lensecond), 5))\n",
    "                except KeyError:\n",
    "                    print(\"error in edit distance\")\n",
    "\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def cos_similarity(q1, q2, model,fittedTFIDF):\n",
    "    \n",
    "    \n",
    "    if len(q1)==0 or len(q2) ==0:\n",
    "        return 0\n",
    "    documents =[]\n",
    "    documents.append(q1)\n",
    "    documents.append(q2)\n",
    "    tfidf_matrix = fittedTFIDF.transform(documents)\n",
    "    matrix = cosine_similarity(tfidf_matrix[0,:], tfidf_matrix[1,:])\n",
    "    return float(matrix[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_google_title =[]\n",
    "soft_SO_title =[]\n",
    "soft_leve_title = []\n",
    "soft_cos_title = []\n",
    "soft_google_body =[]\n",
    "soft_SO_body =[]\n",
    "soft_leve_body = []\n",
    "soft_cos_body = []\n",
    "soft_google_answer =[]\n",
    "soft_SO_answer =[]\n",
    "soft_leve_answer = []\n",
    "soft_cos_answer = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "soft_google =[]\n",
    "soft_SO =[]\n",
    "soft_leve = []\n",
    "soft_cos = []\n",
    "soft_google_it =[]\n",
    "soft_SO_it =[]\n",
    "soft_leve_it = []\n",
    "soft_cos_it = []\n",
    "\n",
    "for i in range(len(df['q1_text_process'])):\n",
    "    \n",
    "        postText = df['q1_text_process'][i] \n",
    "        \n",
    "        relatedPostText =  df['q2_text_process'][i]\n",
    "        \n",
    "        postText_image = df['q1_image_text'][i]\n",
    "        \n",
    "        relatedPostText_image = df['q2_image_text'][i]\n",
    "        \n",
    "\n",
    "        softw2v1 =soft_w2v(postText, relatedPostText, model, tfidf_vectorizer)\n",
    "\n",
    "        soft_google.append(softw2v1)\n",
    "\n",
    "        softw2v2 = soft_w2v(postText, relatedPostText, model2, tfidf_vectorizer)\n",
    "        \n",
    "        soft_SO.append(softw2v2)\n",
    "\n",
    "        \n",
    "        softlev = soft_lev(postText, relatedPostText, model2, tfidf_vectorizer)\n",
    "        \n",
    "        soft_leve.append(softlev)\n",
    "        \n",
    "        soft_cos.append(cos_similarity(postText, relatedPostText, model, tfidf_vectorizer))\n",
    "        \n",
    "        soft_google_it.append(soft_w2v(postText_image, relatedPostText_image, model, its_vectorizer))\n",
    "        \n",
    "        soft_SO_it.append(soft_w2v(postText_image, relatedPostText_image, model2, its_vectorizer))\n",
    "        \n",
    "        soft_leve_it.append(soft_lev(postText_image, relatedPostText_image, model2, its_vectorizer))\n",
    "        \n",
    "        soft_cos_it.append(cos_similarity(postText_image, relatedPostText_image, model, its_vectorizer))\n",
    "    \n",
    "        count = count + 1\n",
    "        \n",
    "        print (count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1={'Id':list(df['Id']), 'class':list(df['class']), 'soft_google':soft_google,'soft_SO':soft_SO,'soft_leve':soft_leve,\n",
    "      'soft_cos':soft_cos, 'soft_google_it':soft_google_it,'soft_SO_it':soft_SO_it,'soft_leve_it':soft_leve_it,\n",
    "      'soft_cos_it':soft_cos_it}\n",
    "model_data=pd.DataFrame(dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2=pd.read_csv(\"RQ3_relatedness_Filtered_data.csv\", encoding = 'latin-1', engine ='python')\n",
    "\n",
    "dict_labels_source = {\"Desktop App image\":0, \"Web browser image\":1, \"Mobile App image\":2, \"User-created Image\":3}\n",
    "dict_labels_purpose = {\"desired output\": 0, \"context\":1}\n",
    "dict_labels_content = {\"User Interface\": 0, \"Results\":1}\n",
    "q1_source=[]\n",
    "q2_source=[]\n",
    "q1_purpose=[]\n",
    "q2_purpose=[]\n",
    "q1_content=[]\n",
    "q2_content=[]\n",
    "for i in range(len(df_2['Id'])):\n",
    "    q1_source.append(dict_labels_source[df_2['q1_source'][i]])\n",
    "    q2_source.append(dict_labels_source[df_2['q2_source'][i]])\n",
    "    q1_purpose.append(dict_labels_purpose[df_2['q1_purpose'][i]])\n",
    "    q2_purpose.append(dict_labels_purpose[df_2['q2_purpose'][i]])\n",
    "    q1_content.append(dict_labels_content[df_2['q1_content'][i]])\n",
    "    q2_content.append(dict_labels_content[df_2['q2_content'][i]])\n",
    "    \n",
    "\n",
    "model_data['image_sim'] = list(df_2['Similarity'])\n",
    "model_data['q1_source'] = list(q1_source)\n",
    "model_data['q2_source'] = list(q2_source)\n",
    "model_data['q1_purpose'] = list(q1_purpose)\n",
    "model_data['q2_purpose'] = list(q2_purpose)\n",
    "model_data['q1_content'] = list(q1_content)\n",
    "model_data['q2_content'] = list(q2_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>class</th>\n",
       "      <th>soft_google</th>\n",
       "      <th>soft_SO</th>\n",
       "      <th>soft_leve</th>\n",
       "      <th>soft_cos</th>\n",
       "      <th>soft_google_it</th>\n",
       "      <th>soft_SO_it</th>\n",
       "      <th>soft_leve_it</th>\n",
       "      <th>soft_cos_it</th>\n",
       "      <th>image_sim</th>\n",
       "      <th>q1_source</th>\n",
       "      <th>q2_source</th>\n",
       "      <th>q1_purpose</th>\n",
       "      <th>q2_purpose</th>\n",
       "      <th>q1_content</th>\n",
       "      <th>q2_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>274</td>\n",
       "      <td>duplicate</td>\n",
       "      <td>0.412504</td>\n",
       "      <td>0.589384</td>\n",
       "      <td>0.370031</td>\n",
       "      <td>0.281318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>314</td>\n",
       "      <td>duplicate</td>\n",
       "      <td>0.813510</td>\n",
       "      <td>0.855175</td>\n",
       "      <td>0.728713</td>\n",
       "      <td>0.695153</td>\n",
       "      <td>0.243018</td>\n",
       "      <td>0.349820</td>\n",
       "      <td>0.151801</td>\n",
       "      <td>0.125719</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>584</td>\n",
       "      <td>duplicate</td>\n",
       "      <td>0.710846</td>\n",
       "      <td>0.827482</td>\n",
       "      <td>0.546367</td>\n",
       "      <td>0.427219</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>605</td>\n",
       "      <td>duplicate</td>\n",
       "      <td>0.888542</td>\n",
       "      <td>0.906706</td>\n",
       "      <td>0.869420</td>\n",
       "      <td>0.823088</td>\n",
       "      <td>0.782101</td>\n",
       "      <td>0.816453</td>\n",
       "      <td>0.795075</td>\n",
       "      <td>0.731419</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>606</td>\n",
       "      <td>duplicate</td>\n",
       "      <td>0.735209</td>\n",
       "      <td>0.728667</td>\n",
       "      <td>0.640454</td>\n",
       "      <td>0.521347</td>\n",
       "      <td>0.266725</td>\n",
       "      <td>0.288690</td>\n",
       "      <td>0.159834</td>\n",
       "      <td>0.041102</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845</th>\n",
       "      <td>343612</td>\n",
       "      <td>isolated</td>\n",
       "      <td>0.394812</td>\n",
       "      <td>0.284807</td>\n",
       "      <td>0.117993</td>\n",
       "      <td>0.050746</td>\n",
       "      <td>0.079116</td>\n",
       "      <td>0.103170</td>\n",
       "      <td>0.014101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846</th>\n",
       "      <td>344643</td>\n",
       "      <td>isolated</td>\n",
       "      <td>0.686622</td>\n",
       "      <td>0.594806</td>\n",
       "      <td>0.555851</td>\n",
       "      <td>0.514593</td>\n",
       "      <td>0.245093</td>\n",
       "      <td>0.286436</td>\n",
       "      <td>0.064742</td>\n",
       "      <td>0.007375</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1847</th>\n",
       "      <td>344649</td>\n",
       "      <td>isolated</td>\n",
       "      <td>0.663317</td>\n",
       "      <td>0.533914</td>\n",
       "      <td>0.488887</td>\n",
       "      <td>0.403396</td>\n",
       "      <td>0.057933</td>\n",
       "      <td>0.053867</td>\n",
       "      <td>0.011848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>345398</td>\n",
       "      <td>isolated</td>\n",
       "      <td>0.558070</td>\n",
       "      <td>0.457995</td>\n",
       "      <td>0.226403</td>\n",
       "      <td>0.127004</td>\n",
       "      <td>0.067871</td>\n",
       "      <td>0.036150</td>\n",
       "      <td>0.023974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>346317</td>\n",
       "      <td>isolated</td>\n",
       "      <td>0.760211</td>\n",
       "      <td>0.746423</td>\n",
       "      <td>0.739959</td>\n",
       "      <td>0.725238</td>\n",
       "      <td>0.201450</td>\n",
       "      <td>0.130599</td>\n",
       "      <td>0.085640</td>\n",
       "      <td>0.073698</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1850 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id      class  soft_google   soft_SO  soft_leve  soft_cos  \\\n",
       "0        274  duplicate     0.412504  0.589384   0.370031  0.281318   \n",
       "1        314  duplicate     0.813510  0.855175   0.728713  0.695153   \n",
       "2        584  duplicate     0.710846  0.827482   0.546367  0.427219   \n",
       "3        605  duplicate     0.888542  0.906706   0.869420  0.823088   \n",
       "4        606  duplicate     0.735209  0.728667   0.640454  0.521347   \n",
       "...      ...        ...          ...       ...        ...       ...   \n",
       "1845  343612   isolated     0.394812  0.284807   0.117993  0.050746   \n",
       "1846  344643   isolated     0.686622  0.594806   0.555851  0.514593   \n",
       "1847  344649   isolated     0.663317  0.533914   0.488887  0.403396   \n",
       "1848  345398   isolated     0.558070  0.457995   0.226403  0.127004   \n",
       "1849  346317   isolated     0.760211  0.746423   0.739959  0.725238   \n",
       "\n",
       "      soft_google_it  soft_SO_it  soft_leve_it  soft_cos_it  image_sim  \\\n",
       "0           0.000000    0.000000      0.000000     0.000000         65   \n",
       "1           0.243018    0.349820      0.151801     0.125719         82   \n",
       "2           0.000000    0.000000      0.000000     0.000000         78   \n",
       "3           0.782101    0.816453      0.795075     0.731419         93   \n",
       "4           0.266725    0.288690      0.159834     0.041102         75   \n",
       "...              ...         ...           ...          ...        ...   \n",
       "1845        0.079116    0.103170      0.014101     0.000000         66   \n",
       "1846        0.245093    0.286436      0.064742     0.007375         67   \n",
       "1847        0.057933    0.053867      0.011848     0.000000         72   \n",
       "1848        0.067871    0.036150      0.023974     0.000000         84   \n",
       "1849        0.201450    0.130599      0.085640     0.073698         60   \n",
       "\n",
       "      q1_source  q2_source  q1_purpose  q2_purpose  q1_content  q2_content  \n",
       "0             0          0           0           0           0           1  \n",
       "1             0          0           0           0           1           1  \n",
       "2             0          0           0           0           0           0  \n",
       "3             0          0           1           1           1           0  \n",
       "4             1          0           1           1           0           0  \n",
       "...         ...        ...         ...         ...         ...         ...  \n",
       "1845          0          2           0           0           1           0  \n",
       "1846          0          1           1           1           0           0  \n",
       "1847          0          0           1           0           0           0  \n",
       "1848          1          0           0           0           1           1  \n",
       "1849          1          0           0           0           0           0  \n",
       "\n",
       "[1850 rows x 17 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>TBA</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "X = model_data[['soft_google','soft_SO','soft_leve','soft_cos']]\n",
    "Y = model_data[['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34594594594594597\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      direct       0.68      0.22      0.33       186\n",
      "   duplicate       0.16      0.64      0.25        42\n",
      "    indirect       0.40      0.35      0.37       101\n",
      "    isolated       0.51      0.61      0.56        41\n",
      "\n",
      "    accuracy                           0.35       370\n",
      "   macro avg       0.44      0.45      0.38       370\n",
      "weighted avg       0.53      0.35      0.36       370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,random_state=880)\n",
    "\n",
    "X_train, Y_train = oversample.fit_resample(X_train,Y_train)\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, Y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "from sklearn import metrics\n",
    "print (metrics.accuracy_score(Y_test, y_pred))\n",
    "print(metrics.classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>TBA + IS</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "X = model_data[['soft_google','soft_SO','soft_leve','soft_cos','image_sim']]\n",
    "Y = model_data[['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34054054054054056\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      direct       0.62      0.20      0.30       186\n",
      "   duplicate       0.18      0.69      0.28        42\n",
      "    indirect       0.35      0.33      0.34       101\n",
      "    isolated       0.50      0.66      0.57        41\n",
      "\n",
      "    accuracy                           0.34       370\n",
      "   macro avg       0.41      0.47      0.37       370\n",
      "weighted avg       0.48      0.34      0.34       370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,random_state=880)\n",
    "\n",
    "X_train, Y_train = oversample.fit_resample(X_train,Y_train)\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, Y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "from sklearn import metrics\n",
    "print (metrics.accuracy_score(Y_test, y_pred))\n",
    "print(metrics.classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>TBA+IS+ITS</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "X = model_data[['soft_google','soft_SO','soft_leve','soft_cos','image_sim', \n",
    "                'soft_google_it','soft_SO_it','soft_leve_it','soft_cos_it']]\n",
    "Y = model_data[['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44594594594594594\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      direct       0.77      0.40      0.52       186\n",
      "   duplicate       0.18      0.48      0.26        42\n",
      "    indirect       0.41      0.44      0.42       101\n",
      "    isolated       0.47      0.66      0.55        41\n",
      "\n",
      "    accuracy                           0.45       370\n",
      "   macro avg       0.46      0.49      0.44       370\n",
      "weighted avg       0.57      0.45      0.47       370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,random_state=880)\n",
    "\n",
    "X_train, Y_train = oversample.fit_resample(X_train,Y_train)\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, Y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "from sklearn import metrics\n",
    "print (metrics.accuracy_score(Y_test, y_pred))\n",
    "print(metrics.classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>TBA+S+C+P</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "X = model_data[['soft_google','soft_SO','soft_leve','soft_cos',\n",
    "                'q1_source','q2_source','q1_purpose','q2_purpose','q1_content','q2_content']]\n",
    "Y = model_data[['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4243243243243243\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      direct       0.61      0.40      0.48       186\n",
      "   duplicate       0.23      0.55      0.33        42\n",
      "    indirect       0.38      0.35      0.36       101\n",
      "    isolated       0.43      0.61      0.51        41\n",
      "\n",
      "    accuracy                           0.42       370\n",
      "   macro avg       0.41      0.48      0.42       370\n",
      "weighted avg       0.49      0.42      0.43       370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,random_state=880)\n",
    "\n",
    "X_train, Y_train = oversample.fit_resample(X_train,Y_train)\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, Y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "from sklearn import metrics\n",
    "print (metrics.accuracy_score(Y_test, y_pred))\n",
    "print(metrics.classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>TBA+IS+S+C+P</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "X = model_data[['soft_google','soft_SO','soft_leve','soft_cos', 'image_sim',\n",
    "                'q1_source','q2_source','q1_purpose','q2_purpose','q1_content','q2_content']]\n",
    "Y = model_data[['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4486486486486487\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      direct       0.64      0.39      0.49       186\n",
      "   duplicate       0.24      0.50      0.33        42\n",
      "    indirect       0.40      0.47      0.43       101\n",
      "    isolated       0.48      0.61      0.54        41\n",
      "\n",
      "    accuracy                           0.45       370\n",
      "   macro avg       0.44      0.49      0.45       370\n",
      "weighted avg       0.51      0.45      0.46       370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,random_state=880)\n",
    "\n",
    "X_train, Y_train = oversample.fit_resample(X_train,Y_train)\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, Y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "from sklearn import metrics\n",
    "print (metrics.accuracy_score(Y_test, y_pred))\n",
    "print(metrics.classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>TBA+ITS+S+C+P</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "X = model_data[['soft_google','soft_SO','soft_leve','soft_cos',\n",
    "                'soft_google_it','soft_SO_it','soft_leve_it','soft_cos_it',\n",
    "                'q1_source','q2_source','q1_purpose','q2_purpose','q1_content','q2_content']]\n",
    "Y = model_data[['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4540540540540541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      direct       0.69      0.42      0.52       186\n",
      "   duplicate       0.21      0.55      0.31        42\n",
      "    indirect       0.43      0.38      0.40       101\n",
      "    isolated       0.48      0.68      0.57        41\n",
      "\n",
      "    accuracy                           0.45       370\n",
      "   macro avg       0.45      0.51      0.45       370\n",
      "weighted avg       0.54      0.45      0.47       370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,random_state=880)\n",
    "\n",
    "X_train, Y_train = oversample.fit_resample(X_train,Y_train)\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, Y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "from sklearn import metrics\n",
    "print (metrics.accuracy_score(Y_test, y_pred))\n",
    "print(metrics.classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>TBA+ITS+S</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "X = model_data[['soft_google','soft_SO','soft_leve','soft_cos',\n",
    "                'soft_google_it','soft_SO_it','soft_leve_it','soft_cos_it',\n",
    "                'q1_source','q2_source']]\n",
    "Y = model_data[['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4027027027027027\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      direct       0.71      0.35      0.47       186\n",
      "   duplicate       0.18      0.52      0.26        42\n",
      "    indirect       0.38      0.35      0.36       101\n",
      "    isolated       0.43      0.63      0.51        41\n",
      "\n",
      "    accuracy                           0.40       370\n",
      "   macro avg       0.42      0.46      0.40       370\n",
      "weighted avg       0.53      0.40      0.42       370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,random_state=880)\n",
    "\n",
    "X_train, Y_train = oversample.fit_resample(X_train,Y_train)\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, Y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "from sklearn import metrics\n",
    "print (metrics.accuracy_score(Y_test, y_pred))\n",
    "print(metrics.classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>TBA+ITS+C</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "X = model_data[['soft_google','soft_SO','soft_leve','soft_cos',\n",
    "                'soft_google_it','soft_SO_it','soft_leve_it','soft_cos_it',\n",
    "                'q1_content','q2_content']]\n",
    "Y = model_data[['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45135135135135135\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      direct       0.76      0.37      0.49       186\n",
      "   duplicate       0.19      0.52      0.28        42\n",
      "    indirect       0.44      0.49      0.46       101\n",
      "    isolated       0.52      0.68      0.59        41\n",
      "\n",
      "    accuracy                           0.45       370\n",
      "   macro avg       0.48      0.51      0.46       370\n",
      "weighted avg       0.58      0.45      0.47       370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,random_state=880)\n",
    "\n",
    "X_train, Y_train = oversample.fit_resample(X_train,Y_train)\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, Y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "from sklearn import metrics\n",
    "print (metrics.accuracy_score(Y_test, y_pred))\n",
    "print(metrics.classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>TBA+ITS+P</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "X = model_data[['soft_google','soft_SO','soft_leve','soft_cos',\n",
    "                'soft_google_it','soft_SO_it','soft_leve_it','soft_cos_it',\n",
    "                'q1_purpose','q2_purpose']]\n",
    "Y = model_data[['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4702702702702703\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      direct       0.69      0.51      0.58       186\n",
      "   duplicate       0.19      0.36      0.25        42\n",
      "    indirect       0.40      0.38      0.39       101\n",
      "    isolated       0.46      0.66      0.54        41\n",
      "\n",
      "    accuracy                           0.47       370\n",
      "   macro avg       0.43      0.47      0.44       370\n",
      "weighted avg       0.53      0.47      0.49       370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,random_state=880)\n",
    "\n",
    "X_train, Y_train = oversample.fit_resample(X_train,Y_train)\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, Y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "from sklearn import metrics\n",
    "print (metrics.accuracy_score(Y_test, y_pred))\n",
    "print(metrics.classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>TBA+ITS+S+C</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "X = model_data[['soft_google','soft_SO','soft_leve','soft_cos',\n",
    "                'soft_google_it','soft_SO_it','soft_leve_it','soft_cos_it',\n",
    "                'q1_source','q2_source','q1_content','q2_content']]\n",
    "Y = model_data[['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4081081081081081\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      direct       0.70      0.32      0.44       186\n",
      "   duplicate       0.20      0.57      0.30        42\n",
      "    indirect       0.39      0.40      0.39       101\n",
      "    isolated       0.44      0.66      0.52        41\n",
      "\n",
      "    accuracy                           0.41       370\n",
      "   macro avg       0.43      0.49      0.41       370\n",
      "weighted avg       0.53      0.41      0.42       370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,random_state=880)\n",
    "\n",
    "X_train, Y_train = oversample.fit_resample(X_train,Y_train)\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, Y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "from sklearn import metrics\n",
    "print (metrics.accuracy_score(Y_test, y_pred))\n",
    "print(metrics.classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>TBA+ITS+S+P</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "X = model_data[['soft_google','soft_SO','soft_leve','soft_cos',\n",
    "                'soft_google_it','soft_SO_it','soft_leve_it','soft_cos_it',\n",
    "                'q1_source','q2_source','q1_purpose','q2_purpose']]\n",
    "Y = model_data[['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44054054054054054\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      direct       0.73      0.37      0.49       186\n",
      "   duplicate       0.19      0.52      0.28        42\n",
      "    indirect       0.44      0.45      0.44       101\n",
      "    isolated       0.44      0.66      0.53        41\n",
      "\n",
      "    accuracy                           0.44       370\n",
      "   macro avg       0.45      0.50      0.44       370\n",
      "weighted avg       0.56      0.44      0.46       370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,random_state=880)\n",
    "\n",
    "X_train, Y_train = oversample.fit_resample(X_train,Y_train)\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, Y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "from sklearn import metrics\n",
    "print (metrics.accuracy_score(Y_test, y_pred))\n",
    "print(metrics.classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>TBA+ITS+C+P</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "X = model_data[['soft_google','soft_SO','soft_leve','soft_cos',\n",
    "                'soft_google_it','soft_SO_it','soft_leve_it','soft_cos_it',\n",
    "                'q1_purpose','q2_purpose','q1_content','q2_content']]\n",
    "Y = model_data[['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46756756756756757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      direct       0.65      0.49      0.56       186\n",
      "   duplicate       0.22      0.48      0.30        42\n",
      "    indirect       0.41      0.34      0.37       101\n",
      "    isolated       0.50      0.66      0.57        41\n",
      "\n",
      "    accuracy                           0.47       370\n",
      "   macro avg       0.45      0.49      0.45       370\n",
      "weighted avg       0.52      0.47      0.48       370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,random_state=880)\n",
    "\n",
    "X_train, Y_train = oversample.fit_resample(X_train,Y_train)\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, Y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "from sklearn import metrics\n",
    "print (metrics.accuracy_score(Y_test, y_pred))\n",
    "print(metrics.classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>TBA+IS+ITS+S+C+P</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "X = model_data[['soft_google','soft_SO','soft_leve','soft_cos','image_sim',\n",
    "                'soft_google_it','soft_SO_it','soft_leve_it','soft_cos_it',\n",
    "                'q1_source','q2_source','q1_purpose','q2_purpose','q1_content','q2_content']]\n",
    "Y = model_data[['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43243243243243246\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      direct       0.65      0.37      0.47       186\n",
      "   duplicate       0.23      0.55      0.32        42\n",
      "    indirect       0.39      0.44      0.41       101\n",
      "    isolated       0.50      0.61      0.55        41\n",
      "\n",
      "    accuracy                           0.43       370\n",
      "   macro avg       0.44      0.49      0.44       370\n",
      "weighted avg       0.51      0.43      0.44       370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,random_state=880)\n",
    "\n",
    "X_train, Y_train = oversample.fit_resample(X_train,Y_train)\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, Y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "from sklearn import metrics\n",
    "print (metrics.accuracy_score(Y_test, y_pred))\n",
    "print(metrics.classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>TBA+IS+ITS+S</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "X = model_data[['soft_google','soft_SO','soft_leve','soft_cos','image_sim',\n",
    "                'soft_google_it','soft_SO_it','soft_leve_it','soft_cos_it',\n",
    "                'q1_source','q2_source']]\n",
    "Y = model_data[['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3675675675675676\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      direct       0.61      0.28      0.38       186\n",
      "   duplicate       0.17      0.60      0.26        42\n",
      "    indirect       0.40      0.34      0.36       101\n",
      "    isolated       0.49      0.61      0.54        41\n",
      "\n",
      "    accuracy                           0.37       370\n",
      "   macro avg       0.42      0.46      0.39       370\n",
      "weighted avg       0.49      0.37      0.38       370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,random_state=880)\n",
    "\n",
    "X_train, Y_train = oversample.fit_resample(X_train,Y_train)\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, Y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "from sklearn import metrics\n",
    "print (metrics.accuracy_score(Y_test, y_pred))\n",
    "print(metrics.classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>TBA+IS+ITS+C</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "X = model_data[['soft_google','soft_SO','soft_leve','soft_cos','image_sim',\n",
    "                'soft_google_it','soft_SO_it','soft_leve_it','soft_cos_it',\n",
    "                'q1_content','q2_content']]\n",
    "Y = model_data[['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4756756756756757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      direct       0.72      0.45      0.56       186\n",
      "   duplicate       0.21      0.45      0.29        42\n",
      "    indirect       0.41      0.46      0.43       101\n",
      "    isolated       0.51      0.66      0.57        41\n",
      "\n",
      "    accuracy                           0.48       370\n",
      "   macro avg       0.46      0.50      0.46       370\n",
      "weighted avg       0.56      0.48      0.49       370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,random_state=880)\n",
    "\n",
    "X_train, Y_train = oversample.fit_resample(X_train,Y_train)\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, Y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "from sklearn import metrics\n",
    "print (metrics.accuracy_score(Y_test, y_pred))\n",
    "print(metrics.classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>TBA+IS+ITS+P</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "X = model_data[['soft_google','soft_SO','soft_leve','soft_cos','image_sim',\n",
    "                'soft_google_it','soft_SO_it','soft_leve_it','soft_cos_it',\n",
    "                'q1_purpose','q2_purpose']]\n",
    "Y = model_data[['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4891891891891892\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      direct       0.74      0.46      0.57       186\n",
      "   duplicate       0.22      0.43      0.29        42\n",
      "    indirect       0.43      0.48      0.45       101\n",
      "    isolated       0.48      0.71      0.57        41\n",
      "\n",
      "    accuracy                           0.49       370\n",
      "   macro avg       0.47      0.52      0.47       370\n",
      "weighted avg       0.57      0.49      0.51       370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,random_state=880)\n",
    "\n",
    "X_train, Y_train = oversample.fit_resample(X_train,Y_train)\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, Y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "from sklearn import metrics\n",
    "print (metrics.accuracy_score(Y_test, y_pred))\n",
    "print(metrics.classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>TBA+IS+ITS+S+C</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "X = model_data[['soft_google','soft_SO','soft_leve','soft_cos','image_sim',\n",
    "                'soft_google_it','soft_SO_it','soft_leve_it','soft_cos_it',\n",
    "                'q1_source','q2_source','q1_content','q2_content']]\n",
    "Y = model_data[['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3972972972972973\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      direct       0.62      0.29      0.40       186\n",
      "   duplicate       0.20      0.57      0.29        42\n",
      "    indirect       0.39      0.44      0.41       101\n",
      "    isolated       0.50      0.61      0.55        41\n",
      "\n",
      "    accuracy                           0.40       370\n",
      "   macro avg       0.43      0.48      0.41       370\n",
      "weighted avg       0.50      0.40      0.41       370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,random_state=880)\n",
    "\n",
    "X_train, Y_train = oversample.fit_resample(X_train,Y_train)\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, Y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "from sklearn import metrics\n",
    "print (metrics.accuracy_score(Y_test, y_pred))\n",
    "print(metrics.classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>TBA+IS+ITS+S+P</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "X = model_data[['soft_google','soft_SO','soft_leve','soft_cos','image_sim',\n",
    "                'soft_google_it','soft_SO_it','soft_leve_it','soft_cos_it',\n",
    "                'q1_source','q2_source','q1_purpose','q2_purpose']]\n",
    "Y = model_data[['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4135135135135135\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      direct       0.66      0.34      0.45       186\n",
      "   duplicate       0.19      0.55      0.28        42\n",
      "    indirect       0.41      0.41      0.41       101\n",
      "    isolated       0.49      0.61      0.54        41\n",
      "\n",
      "    accuracy                           0.41       370\n",
      "   macro avg       0.44      0.48      0.42       370\n",
      "weighted avg       0.52      0.41      0.43       370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,random_state=880)\n",
    "\n",
    "X_train, Y_train = oversample.fit_resample(X_train,Y_train)\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, Y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "from sklearn import metrics\n",
    "print (metrics.accuracy_score(Y_test, y_pred))\n",
    "print(metrics.classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>TBA+IS+ITS+C+P</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "X = model_data[['soft_google','soft_SO','soft_leve','soft_cos','image_sim',\n",
    "                'soft_google_it','soft_SO_it','soft_leve_it','soft_cos_it',\n",
    "                'q1_purpose','q2_purpose','q1_content','q2_content']]\n",
    "Y = model_data[['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4837837837837838\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      direct       0.79      0.40      0.53       186\n",
      "   duplicate       0.25      0.50      0.33        42\n",
      "    indirect       0.41      0.56      0.47       101\n",
      "    isolated       0.51      0.66      0.57        41\n",
      "\n",
      "    accuracy                           0.48       370\n",
      "   macro avg       0.49      0.53      0.48       370\n",
      "weighted avg       0.59      0.48      0.50       370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,random_state=880)\n",
    "\n",
    "X_train, Y_train = oversample.fit_resample(X_train,Y_train)\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, Y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "from sklearn import metrics\n",
    "print (metrics.accuracy_score(Y_test, y_pred))\n",
    "print(metrics.classification_report(Y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
